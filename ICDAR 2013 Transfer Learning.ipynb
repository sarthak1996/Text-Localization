{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as nnFunctions\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import newaxis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TempTest Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a=np.zeros((1,512,512)).astype(np.float32)\n",
    "b=np.ones((1,512,512)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a=a[...,newaxis]\n",
    "b=b[...,newaxis]\n",
    "a=np.transpose(a,[0,3,1,2])\n",
    "b=np.transpose(a,[0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_data=np.fromfile('trainImagesNumpy_512x512_color.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_data=np_data.reshape(410,512,512,-1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_data=np.transpose(np_data,[0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_labels=np.fromfile('trainMaskNumpy_512x512.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_labels=np_labels.reshape(410,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_labels=np_labels.astype(np.float32)[...,newaxis]\n",
    "np_labels=np.transpose(np_labels,[0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features and Label Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=torch.from_numpy(np_data)\n",
    "targets=torch.from_numpy(np_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "train_data = data_utils.TensorDataset(features, targets)\n",
    "train_loader = data_utils.DataLoader(train_data, batch_size=batch_size, shuffle=True,num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myConvNet(nn.Module):\n",
    "    #constructor\n",
    "    def __init__(self):\n",
    "        super(myConvNet, self).__init__()\n",
    "        #defining layers in convnet\n",
    "        #input size=1*657*1625\n",
    "        self.conv1 = nn.Conv2d(512,512, kernel_size=3,stride=1,padding=1)\n",
    "        self.conv2 = nn.Conv2d(512,256, kernel_size=3,stride=1,padding=1)\n",
    "        #self.bn1=nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1)\n",
    "        self.pconv1= nn.Conv2d(256,128, kernel_size=(3,3),stride=1,padding=(1,1))\n",
    "        #self.bn2=nn.BatchNorm2d(64)\n",
    "        self.pconv2= nn.Conv2d(256,128, kernel_size=(3,7),stride=1,padding=(1,3))\n",
    "        self.pconv3= nn.Conv2d(256,128, kernel_size=(7,3),stride=1,padding=(3,1))\n",
    "        \n",
    "        self.conv4= nn.Conv2d(128,64,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv5= nn.Conv2d(64,1,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "    def forward(self, x,index1,index2,index3,index4):\n",
    "        x = nnFunctions.max_unpool2d(nnFunctions.leaky_relu(self.conv1(x)),indices=index4,kernel_size=(2,2),stride=(2,2))\n",
    "        x = nnFunctions.leaky_relu(self.conv2(x))\n",
    "        x = nnFunctions.max_unpool2d(nnFunctions.leaky_relu(self.conv3(x)),indices=index3,kernel_size=(2,2),stride=(2,2))\n",
    "        #parallel conv\n",
    "        x = nnFunctions.max_unpool2d(nnFunctions.leaky_relu(self.pconv1(x)+self.pconv2(x)+self.pconv3(x)),indices=index2,kernel_size=(2,2),stride=(2,2))\n",
    "        \n",
    "        x = nnFunctions.max_unpool2d(nnFunctions.leaky_relu(self.conv4(x)),indices=index1,kernel_size=(2,2),stride=(2,2))\n",
    "        x = nnFunctions.leaky_relu(self.conv5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_net=myConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16=torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modified_pretrained = nn.Sequential(*list(vgg16.features.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class finalConvNet(nn.Module):\n",
    "    global index1,index2,index3,index4\n",
    "    #constructor\n",
    "    def __init__(self,mynet,vgg16):\n",
    "        super(finalConvNet, self).__init__()\n",
    "        self.vgg=vgg16\n",
    "        self.custom_net=mynet\n",
    "        \n",
    "        for i in range(30):\n",
    "            if(i<14):\n",
    "                self.vgg[i].requires_grad=False\n",
    "            else:\n",
    "                self.vgg[i].requires_grad=True\n",
    "            if(i==4):\n",
    "                self.vgg[i].return_indices=True\n",
    "            elif(i==9):\n",
    "                self.vgg[i].return_indices=True\n",
    "            elif(i==16):\n",
    "                self.vgg[i].return_indices=True\n",
    "            elif(i==23):\n",
    "                self.vgg[i].return_indices=True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #4 max pool layers\n",
    "        for layers in range(30):\n",
    "            if(layers==4):\n",
    "                x,index1=self.vgg[layers](x)\n",
    "            elif(layers==9):\n",
    "                x,index2=self.vgg[layers](x)\n",
    "            elif(layers==16):\n",
    "                x,index3=self.vgg[layers](x)\n",
    "            elif(layers==23):\n",
    "                x,index4=self.vgg[layers](x)\n",
    "            else:\n",
    "                x=self.vgg[layers](x)\n",
    "        x=self.custom_net(x,index1,index2,index3,index4)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net=finalConvNet(my_net,modified_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion=nn.L1Loss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(epoch, init_lr=learning_rate, lr_decay_epoch=10):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr=init_lr\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader,net,epochs,total_samples,lr_scheduler):\n",
    "    global learning_rate\n",
    "    prev_loss=0\n",
    "    net.train()\n",
    "    \n",
    "    \n",
    "    for epoch in range(int(epochs)): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        learning_rate = lr_scheduler(epoch)\n",
    "        \n",
    "        optimizer = optim.Adam(net.parameters(),lr=learning_rate)\n",
    "        \n",
    "        for i,data in enumerate(train_loader):\n",
    "            inputs,labels=data\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()        \n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            cur_loss=loss.data[0]\n",
    "            print '{0}\\r'.format('Batch '+str(i)+':'+str(cur_loss)),\n",
    "        running_loss=running_loss\n",
    "        print('\\n\\t Iteration '+str(epoch)+':'+str(running_loss))\n",
    "        if(epoch%2==0):\n",
    "            print('Saving network')\n",
    "            net.cpu()\n",
    "            torch.save(net,'Net_checkpoints/net_transfer_learning_4_correct_images_intermediate_'+str(epoch/2)+'.txt')\n",
    "            net.cuda()\n",
    "#         if(prev_loss<running_loss):\n",
    "#             learning_rate/=10\n",
    "        prev_loss=running_loss\n",
    "    print('Finished Training')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net=train(train_loader,net,10,410,exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net,'net_transfer_learning_5_correct_images.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
