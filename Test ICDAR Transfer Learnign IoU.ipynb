{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch.nn.functional as nnFunctions\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import skimage.io as io\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myConvNet(nn.Module):\n",
    "    #constructor\n",
    "    def __init__(self):\n",
    "        super(myConvNet, self).__init__()\n",
    "        #defining layers in convnet\n",
    "        #input size=1*657*1625\n",
    "        self.conv1 = nn.Conv2d(512,512, kernel_size=3,stride=1,padding=1)\n",
    "        self.conv2 = nn.Conv2d(512,256, kernel_size=3,stride=1,padding=1)\n",
    "        #self.bn1=nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1)\n",
    "        self.pconv1= nn.Conv2d(256,128, kernel_size=(3,3),stride=1,padding=(1,1))\n",
    "        #self.bn2=nn.BatchNorm2d(64)\n",
    "        self.pconv2= nn.Conv2d(256,128, kernel_size=(3,7),stride=1,padding=(1,3))\n",
    "        self.pconv3= nn.Conv2d(256,128, kernel_size=(7,3),stride=1,padding=(3,1))\n",
    "        \n",
    "        self.conv4= nn.Conv2d(128,64,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv5= nn.Conv2d(64,1,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "    def forward(self, x,index1,index2,index3,index4):\n",
    "        x = nnFunctions.max_unpool2d(nnFunctions.relu(self.conv1(x)),indices=index4,kernel_size=(2,2),stride=(2,2))\n",
    "        x = nnFunctions.relu(self.conv2(x))\n",
    "        x = nnFunctions.max_unpool2d(nnFunctions.relu(self.conv3(x)),indices=index3,kernel_size=(2,2),stride=(2,2))\n",
    "        #parallel conv\n",
    "        x = nnFunctions.max_unpool2d(nnFunctions.relu(self.pconv1(x)+self.pconv2(x)+self.pconv3(x)),indices=index2,kernel_size=(2,2),stride=(2,2))\n",
    "        \n",
    "        x = nnFunctions.max_unpool2d(nnFunctions.relu(self.conv4(x)),indices=index1,kernel_size=(2,2),stride=(2,2))\n",
    "        x = nnFunctions.relu(self.conv5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16=torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modified_pretrained = nn.Sequential(*list(vgg16.features.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class finalConvNet(nn.Module):\n",
    "    global index1,index2,index3,index4\n",
    "    #constructor\n",
    "    def __init__(self,mynet,vgg16):\n",
    "        super(finalConvNet, self).__init__()\n",
    "        self.vgg=vgg16\n",
    "        self.custom_net=mynet\n",
    "        \n",
    "        for i in range(30):\n",
    "            if(i<14):\n",
    "                self.vgg[i].requires_grad=False\n",
    "            else:\n",
    "                self.vgg[i].requires_grad=True\n",
    "            if(i==4):\n",
    "                self.vgg[i].return_indices=True\n",
    "            elif(i==9):\n",
    "                self.vgg[i].return_indices=True\n",
    "            elif(i==16):\n",
    "                self.vgg[i].return_indices=True\n",
    "            elif(i==23):\n",
    "                self.vgg[i].return_indices=True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #4 max pool layers\n",
    "        for layers in range(30):\n",
    "            if(layers==4):\n",
    "                x,index1=self.vgg[layers](x)\n",
    "            elif(layers==9):\n",
    "                x,index2=self.vgg[layers](x)\n",
    "            elif(layers==16):\n",
    "                x,index3=self.vgg[layers](x)\n",
    "            elif(layers==23):\n",
    "                x,index4=self.vgg[layers](x)\n",
    "            else:\n",
    "                x=self.vgg[layers](x)\n",
    "        x=self.custom_net(x,index1,index2,index3,index4)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net=torch.load('Net_checkpoints/net_transfer_learning_5_intermediate5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finalConvNet (\n",
       "  (vgg): Sequential (\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU (inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU (inplace)\n",
       "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU (inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU (inplace)\n",
       "    (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU (inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU (inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU (inplace)\n",
       "    (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU (inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU (inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU (inplace)\n",
       "    (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU (inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU (inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU (inplace)\n",
       "  )\n",
       "  (custom_net): myConvNet (\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pconv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pconv2): Conv2d(256, 128, kernel_size=(3, 7), stride=(1, 1), padding=(1, 3))\n",
       "    (pconv3): Conv2d(256, 128, kernel_size=(7, 3), stride=(1, 1), padding=(3, 1))\n",
       "    (conv4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_data=np.fromfile('testImagesNumpy_512x512_color.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110886912,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_data=np_data.reshape(141,512,512,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import newaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_data=np_data.astype(np.float32)\n",
    "np_data=np.transpose(np_data,[0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 3, 512, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_labels=np.fromfile('testMaskNumpy_512x512_color.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36962304,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_labels=np_labels.reshape(141,512,512,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_labels=np_labels.astype(np.float32)\n",
    "np_labels=np.transpose(np_labels,[0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 1, 512, 512)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=torch.from_numpy(np_data)\n",
    "targets=torch.from_numpy(np_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display = data_utils.TensorDataset(features,targets)\n",
    "display_loader = data_utils.DataLoader(display, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToMask(predicted):\n",
    "    for i in range(predicted.shape[0]):\n",
    "        for j in range(predicted.shape[1]):\n",
    "            for k in range(predicted.shape[2]):\n",
    "                for l in range(predicted.shape[3]):\n",
    "                    if(predicted[i][j][k][l]>200):\n",
    "                        predicted[i][j][k][l]=255\n",
    "                    else:\n",
    "                        predicted[i][j][k][l]=0\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersection=0\n",
    "union=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 35Processed"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(display_loader):\n",
    "    inputs,mask=data\n",
    "    # wrap them in Variable\n",
    "    inputs=Variable(inputs).cuda()\n",
    "    predicted = net(inputs)\n",
    "    predicted=predicted.data.cpu().numpy()\n",
    "    predicted=convertToMask(predicted)\n",
    "    mask=mask.numpy()\n",
    "    print (\"\\r Batch \"+str(i)+\"Processed\",end=\"\")\n",
    "    sys.stdout.flush()\n",
    "    intersection+= np.sum( (mask*predicted) > 0 )\n",
    "    union+=np.sum( (mask+predicted) > 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU0.609002965648\n"
     ]
    }
   ],
   "source": [
    "print(\"IoU\"+str((intersection)/(1.0*union)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
